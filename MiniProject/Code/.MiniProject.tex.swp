\documentclass[11pt, a4paper]{article} % A4 paper size, 11pt font size

\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[T1]{fontenc} % Output font encoding for international characters
\usepackage{fouriernc} % Use the New Century Schoolbook font
\usepackage{lineno} % Allows for linenumbers (many customisable options)
\usepackage{graphicx} % Allows for the isertion of pictures files: PNG, JPEG, PDF, GIF. Also from different directories
\usepackage[margin = 2cm]{geometry} % Applies a margin width of 2cm
\renewcommand{\familydefault}{\sfdefault} % Ariel font
\usepackage{natbib} % Allows for author name-year citations
\usepackage{textcomp} % Allows for degrees celcius symbol


\begin{document}

\begin{titlepage} % Suppresses headers and footers on the title page

	\centering % Centre everything on the title page
	
	\vspace*{\baselineskip} % White space at the top of the page
	
	\rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt} % Thick horizontal rule
	\rule{\textwidth}{0.4pt} % Thin horizontal rule
	
	\vspace{0.75\baselineskip} % Whitespace above the title
	
	{\huge How well do different mathematical models, e.g., based upon population growth (mechanistic) theory vs. phenomenological ones, fit to functional responses data across species?} % TITLE
	
	\vspace{0.75\baselineskip} % Whitespace below the title
	
	\rule{\textwidth}{0.4pt}\vspace*{-\baselineskip}\vspace{3.2pt} % Thin horizontal rule
	\rule{\textwidth}{1.6pt} % Thick horizontal rule
		
	\vspace{2\baselineskip} % Whitespace after the title block
	
	{\LARGE Ryan Ellis} % Large authour Name
	\vspace*{0.75\baselineskip} % Whitespace under the subtitle
	
	\Large % All the following text a little larger
	Computational Methods in Ecology and Evolution MRes
	\vspace*{0.75\baselineskip} % Whitespace under Further description
	
	2019 - 2020
	\vspace*{0.75\baselineskip} % Whitespace under year

	ryan.ellis19@imperial.ac.uk
	\vspace*{3\baselineskip} % Whitespace under email address
	
	Imperial College London
			
	
\end{titlepage}

\linenumbers % Default of continuous line numbers on the left hand side of the page hereafter
\linespread{2} % A line spacing of 1.5 hereafter

\section{Abstract}

\section{Introduction}

With recent advancements in computing power and programming ability within the scientific community, biologists are increasingly seeking to model more complex data with more complex models \citep{RN69}. This has given rise to a shift in the methods of analysing data. As opposed to the more traditional method of null hypothesis testing, computing power, combined with mathematical applications in biology and awareness, has resulted in the emergence of model selection, upon which to make biological inferences \citep{RN68}. One such industry within biology that has adopted this more complex approach of mathematical modelling on a large scale, is food microbiology \citep{RN108, RN105}. The ability to model and predict bacterial growth data has clear ramifications for the food industry, particularly with regard to the shelf life of food, food spoilage and food poisoning can all be directly related to bacterial growth \citep{RN106}. This has microbiologists using many different modelling techniques and models in order to develop a model that best fits and describes functional response data, in the form of bacterial population growth. Many types of models exist, falling into two categories: phenomenological and mechanistic. Phenomenological models only seek to describe the data being modelled, whereas mechanistic models seek to describe and mathematically explain the phenomena observed in the data. This study aims to shed light on the advantages and disadvantages to using both types, and ultimately answer which type is better in modelling functional response data across species, in the form of bacterial population growth.
\paragraph{} Model selection can thus offer clear advantages to data representation and predictive power in biology and its associated industries. The theoretical bacterial growth curve can be broken down into four main stages: the lag phase, exponential growth phase, stationary phase and death phase \citep{RN106}. The lag phase exists because of the delay in growth due to the time taken for the bacteria to change the gene expression, and prepare their transcriptome and proteome for growth in a nascent environment. Once the microbes are primed for growth however, this sees the transition into the second phase of the growth curve, the exponential phase. In this phase, bacteria multiply via mitosis at an exponential rate, doubling with every mitotic cycle. The population growth enters the stationary phase when resources are no longer in excess and become rate limiting. Now the population has reached carrying capacity, where the death rate equals that of mitosis. Finally, the death phase occurs when resources deplete, rendering the death rate greater than the rate of reproduction. However, due to most food spoilage and food poisoning as a result of bacterial growth long before the death phase, the data collected for the growth curve of particular interest to industry and thus biology, resembles that of a sigmoidal curve \citep{RN110}. Due to this sigmoidal relationship between time and population biomass, three widely used and popular non-linear models will be tested against one another: the classic logistic \citep{RN106}, Gompertz \citep{RN73} and Baranyi model \citep{RN110}, along with three polynomial phenomenological models: linear regression, quadratic and cubic. These particular non-linear and mechanistic models were chosen due to their design in capturing the sigmoidal relationship of bacterial population growth data. On the other hand, the phenomenological polynomials were chosen for their simplicity and familiarity among biologists. 


%What is modelling and why - done
%phenomenological models vs mechenistic
%why polynomials, why logisitic, Gompertz and Baranyi

\section{Data}

The initial dataset, called "LogisticGrowthData.csv", is an accumulation of data collected from many different studies regarding bacterial population growth. Such studies varied in the bacterial species and strains used and observed their growth rates over time, while varying the environment temperature and media the populations were exposed to. Of the many columns of data, all explained in "LogisticGrowthMetaData.csv", the relationship between the bacterial population biomass (PopBio) and time (Time) was of the most interest, taking into account of the species (Species), media (Medium) and temperature (Temp) used in each instance.

\section{Methods}

\subsection{Data Exploration and Visualisation}

To begin the project, exploration and visualisation of the data was essential. To do this, a custom script in R was written, called "LG\_DiagnosticPlot.R" to create diagnostic plots of the data. The data was grouped according to species and diagnostic scatter plots drawn, one colour for each temperature, and wrapped by each medium used for that species. This yielded .png files for each species, with scatter plots for each medium used for that species, with the points plotted and colour coded for each temperature within each plot. Diagnostic plots such as these were essential in visualising the data to explore any visual trends. From these scatter plots, it was notable most datasets of each unique combination of species, medium and temperature, increased in bacterial population biomass as time increased. More specifically, the overall trend of the data visually was indeed that of a logistic population growth. Characteristic of logistic growth, we have an initial lag phase, followed by an exponential growth phase, finally reaching a plateau of population growth as the population reach the carrying capacity of the environment.

\subsection{The Mathematical Models}

A total of six models were used in order to investigate whether phenomenological or mechanistic models, based on population growth, fit better to the functional responses data across the bacterial species. An even split of three phenomenological models and three mechanistic models were used. The phenomenological models used were three linear polynomial models: regression, quadratic and cubic.
\paragraph{} On the other hand, the three mechanistic models chosen were all non-linear, using mathematics to describe logistic population growth. The fist model to be tested was the classic logistic equation:

\begin{equation}
N_t = \frac{(N_0 * N_{max} * e^{r_{max} * t})} {(N_{max} + N_0 * (e^{r_{max} * t} - 1))}
\label{eqn:logistic}
\end{equation}
where:
\begin{itemize}
\item $N_t$ = population biomass at time t
\item $N_0$ = initial population size
\item $N_{max}$ = maximum carrying capacity
\item $r_{max}$ = maximum growth rate
\item t = time
\end{itemize}

\paragraph{} The second mechanistic model to be tested was the modified Gompertz equation: 

\begin{equation}
N_t = (N_0 + (N_{max} - N_0) * \frac{e^{-e^{r_{max} * e * (t_{lag} - t)}}} {(N_{max} - N_0) * ln(10) + 1}
\label{eqn:Gompertz}
\end{equation}
where:
\begin{itemize}
\item $N_t$ = population biomass at time t
\item $N_0$ = initial population size
\item $N_{max}$ = maximum carrying capacity
\item $r_{max}$ = maximum growth rate 
\item t = time
\item $t_{lag}$ = time interface between the initial lag phase and the exponential growth phase
\end{itemize}

\paragraph{} The third and final mechanistic model to be assessed was the Baranyi model:

\begin{equation}
N_t = N_{max} + log(\frac{-1 + e^{r_{max} * t_{lag}) + e^{r_{max} * t}}}{e^{r_{max} * t} - 1 + e^{r_{max} * t_{lag}} * 10^{n_{max} - N_0}})
\label{eqn:Baranyi}
\end{equation}
where:
\begin{itemize}
\item $N_t$ = population biomass at time t
\item $N_0$ = initial population size
\item $N_{max}$ = maximum carrying capacity
\item $r_{max}$ = maximum growth rate
\item t = time
\item $t_{lag}$ = time interface between the initial lag phase and the exponential growth phase
\end{itemize}

\subsection{Model Fitting}

In order to fit the models to the "LogisticGrowthData.csv" dataset, a custom R script was written, called "models\_all.R". models\_all.R takes the original dataset and starts by cleaning the data e.g any negative values for population biomass are removed, as these observations are illogical. The script then proceeds to group the observations by each unique combination of temperature, medium and species, before assigning an identification column with unique IDs for each unique group of data. This creates 285 datasets of observations corresponding to these IDs, whereby we have all the population biomass data recorded over time for each ID in a separate dataframe. 
\paragraph{} Once the data has been cleaned and reformatted, the three mathematical equations: logistic (Equation \ref{eqn:logistic}), Gompertz (Equation \ref{eqn:Gompertz}) and Baranyi (Equation \ref{eqn:Baranyi}), are defined as functions for model fitting. Following this, models\_all.R will then loop through all the unique ID datasets in an iterative process to carrying out a number of tasks on the data. Initially, it will estimate all the starting parameters ($N_0$, $N_{max}$, $r_{max}$ and $t_{lag}$) necessary of that dataset to attempt fitting the mechanistic non-linear models. Once starting parameters are estimated, each of the six models (regression, quadratic, cubic, logistic (Equation \ref{eqn:logistic}), Gompertz (Equation \ref{eqn:Gompertz}) and Baranyi (Equation \ref{eqn:Baranyi})) are modelled to the data. Immediately after a model is fitted, the AIC of the model fit is calculated. If however, the non-linear models do not converge and thus do not fit the data, the AIC of this model is recorded at NA. After all six models have been fitted to the data (or at least attempted to fit), and their corresponding AICs have been calculated, the AIC information for each model along with the dataset ID is stored in a dataframe that will later be written and exported in a "StatsResults.csv" file.
\paragraph{} After all six models have been fitted and coefficients thus worked out (or not if the models failed to converge), models\_all.R then seeks to plot the dataset, along with all the models overlaid that successfully converged. It does this by using the optimised parameters, previously calculated in the model fitting step, unique to each of the models and overlays the predicted graph onto the scatter plot of the data. If the model was unsuccessful and failed to converge on this dataset, rendering the AIC value NA, then the graph of the model is not attempted to be made and plotted. This plot, along with its many graphs is then saved and exported as a .png file. This completes one iteration on one ID dataset, and the cycle continues through all ID datasets, producing 285 rows of AIC data and 285 scatter plots with the successful models plotted.



\subsection{Model Fitting Analysis}

For the final analysis, another R script "fit\_analysis.R" was written to perform analysis of the AIC values stored in "StatsResults.csv". This scripts begins by calculating what percentage of datasets each model fitted. Following this, of all 285 datasets, the script calculates what percentage of the datasets did each model perform the best and acheive the lowest AIC value, and thirdly, of the datasets each model actually converges on and fits, the percentage of those each model fitted the est for with the lowest AIC. All these percentage analyses are written into another comma separated values file called "AIC\_percentages.csv" (Table \ref{tab:results}). For ease of visual representation, this csv file is then reformatted into "AIC\_percentages2.csv" and a grouped bar plot is then constructed Figure \ref{fig:barplot}. 

\subsection{Computing Tools}

\subsubsection{Bash}

Bash as a scripting language in this project was used to write "Compile\_MiniProject.sh" in order to compile the Latex script "MiniProject.tex" into the final written report as a pdf file. 

\subsubsection{Python}

Another scripting language, Python, was used in creating the "run\_MiniProject.py" script. This script was written as a pipeline wrapper to run all the other scripts in research project in correct order. This enables a clean execution of the pipeline in order to go from raw data to final results and pdf report from running one single script. 

\subsubsection{R}

R was instrumental to the project, having written most of the code in R and three major scripts: LG\_DiagnosticPlot.R (see Methods: Data Exploration and Visualisation), models\_all.R (see Methods: Model Fitting) and fit\_analysis.R (see Methods: Model Fitting Analysis). Each of the scripts were mostly written in base R, however, three packages were used. While ggplot2 was used for superior creation of plots, in all three scripts, tidyr was used in LG\_DiagnosticPlot.R and models\_all.R for wrangling the datasets with the nest() function. The third package in R was minpack.lm, used in models\_all.R, for the function nlsLM() which sought convergence of the non-linear models and optimisation of the parameters.

\section{Results}

After fitting both phenomenological and mechanistic models to the bacterial population growth data across 45 different species and strains, with 285 different unique combinations of species, medium and temperature, it is clear that overall the polynomial phenomenological models most consistently fit the data. Table \ref{tab:results} below illustrates the results of the models fitting. The phenomenological models were the most frequent at converging on the data with: 100\%, 100\% and 97.9\% convergence success rate for the regression, quadratic and cubic models, respectively. With regard to the mechanistic models, the logistic equation was much lower, at 43.9\% convergence success, with the lowest success rate of 35.8\% from the Baranyi model. However, by far the most frequently fitting mechanistic model to the data was the Gompertz model with a 95.8\% converging success rate. The results shown in Table \ref{tab:results} is illustrated below graphically in a grouped bar chart in Figure \ref{fig:barplot}.

\begin{table}[h]
\scalebox{0.9}{
\begin{tabular}{|l|l|l|l|}
Model & A) Best Fit Overall (\%) & B) Convergence (\%) & C) Best Fit for Converged Datasets (\%) \\
\hline
Regression & 3.2 & 100 & 3.2 \\
Quadratic & 7.4 & 100 & 7.4 \\
Cubic & 23.9 & 97.9 & 24.4 \\
Logistic & 6.7 & 43.9 & 15.2 \\
Gompertz & 53.3 & 95.8 & 55.7 \\
Baranyi & 5.6 & 35.8 & 15.7 \\
\end{tabular}}
\caption{\textbf{A)} The percentage for which the model is the best fitting model across all dataset IDs. \textbf{B)} The percentage for which the model fits all dataset IDs. \textbf{C)} Of the dataset IDs the model fits (B), the percentage for which it fits the dataset IDs the best.}
\label{tab:results}
\end{table}

\begin{figure}[h]
\centering
\includegraphics[width=110mm]{../Results/AIC_percentages_results_reformatted.png}
\caption{\textbf{A)} The percentage for which the model is the best fitting model across all dataset IDs. \textbf{B)} The percentage for which the model fits all dataset IDs. \textbf{C)} Of the dataset IDs the model fits (B), the percentage for which it fits the dataset IDs the best.}
\label{fig:barplot}
\end{figure}

\paragraph{} With the regression, quadratic, cubic and Gompertz models fitting at a rate of over 95\%, and logistic (43.9\%) and Baranyi (35.8\%) much lower, consequently a lot of the datasets are only fitted by the phenomenological models and Gompertz (Figure \ref{fig:common}). The Gompertz model also fits the best overall at by far the best rate, at 53.3\% of the time, with cubic at 23.9\%, quadratic 7.4\% and regression 3.2\% (Table \ref{tab:results}). These results are reflected in Figure \ref{fig:common}, with the four most frequently converging models plotted, with each model visually representing the data in order of there best fit percentage overall. Despite the logistic and Baranyi models having the lowest convergence percentage on the datasets, and having relatively low best fit percentage across all the datasets, 6.7\% and 5.6\% (Table \ref{tab:results}), respectively, however, when the two models do fit the datasets, their best fit percentage increases dramatically: consequently, we observe nearly a 3-fold increase in the rate at which they achieve the lowest AIC score among all the models, with logistic achieving a best fit percentage of 15.2\% and Baranyi a similar 15.7\%. This is reflected in Figure \ref{fig:models}, which illustrates that when logisitc and Baranyi do converge on the data and fit, they do fit very well.

\begin{figure}[h]
\centering
\includegraphics[width=100mm]{../Results/Weissella-viridescens_MRS-broth_4.png} % \includegraphics does NOT like WHITESPACE OR EXTRA full stops in figure names
\caption{A plot showing the for most frequently converging models: regression, quadratic, cubic and Gompertz. Here, the Gompertz model is modelling the data best. The dataset here is \textit{Weissella viridescens} on a MRS broth medium at 7\textcelsius{}.}
\label{fig:common}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=110mm]{../Results/Enterobacter-sp-_TSB_35.png}
\caption{A plot showing all the models converging on the dataset where \textit{Enterobacter sp} is growing on a TSB medium at 35\textcelsius{}.}
\label{fig:models}
\end{figure}


\section{Discussion}



\bibliographystyle{plainnat} % author name-year citations
\bibliography{../Data/MiniProject}


\end{document}